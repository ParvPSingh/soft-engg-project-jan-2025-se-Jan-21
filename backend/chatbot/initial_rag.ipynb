{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_together import ChatTogether, TogetherEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatTogether(\n",
    "    model=\"deepseek-ai/DeepSeek-V3\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessage(\n",
    "    content=\"You are Autobot, an IITM BS degree virtual assistant for the students of the BS Data Science program. You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,  # System prompt\n",
    "    MessagesPlaceholder(variable_name=\"retrieved_context\"),\n",
    "    (\"human\", \"{user_query}\") \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['retrieved_context', 'user_query'], input_types={'retrieved_context': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7215402fb100>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessage(content=\"You are Autobot, an IITM BS degree virtual assistant for the students of the BS Data Science program. You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\", additional_kwargs={}, response_metadata={}), MessagesPlaceholder(variable_name='retrieved_context'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_query'], input_types={}, partial_variables={}, template='{user_query}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "autobot = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"./assets/Intro-to-python.md\")\n",
    "documents = loader.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 720 , chunk_overlap = 72\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Intro to Python Programming - Course Information\\n\\n## Grading Information\\n\\n### Quiz Dates:\\n- **Quiz 1:** February 23, 2025\\n- **Quiz 2:** No Quiz 2\\n- **End Term Exam:** April 13, 2025\\n\\n### Programming Exams (OPPE):\\n- **OPPE1:** Sunday, March 2, 2025\\n- **OPPE2:** Sunday, April 6, 2025\\n\\n### OPPE Slot Allocation:\\nDepending on eligibility for OPPE1 & OPPE2, students will be allocated one of three slots. Ensure availability on the given dates.\\n\\n### Eligibility for Bonus:\\n- The **SCT (System Compatibility Test)** is mandatory for the bonus to be added to the final score.\\n- Attendance in mock tests alone does **not** qualify for the bonus.\\n\\n## Eligibility Criteria'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = TogetherEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.from_documents(chunks , embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reterive_context(user_query):\n",
    "    \n",
    "    docs = vector_store.similarity_search(user_query, k=3)\n",
    "    content =  \"\\n\".join([doc.page_content for doc in docs])\n",
    "    return [SystemMessage(content=content)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='# Intro to Python Programming - Course Information\\n\\n## Grading Information\\n\\n### Quiz Dates:\\n- **Quiz 1:** February 23, 2025\\n- **Quiz 2:** No Quiz 2\\n- **End Term Exam:** April 13, 2025\\n\\n### Programming Exams (OPPE):\\n- **OPPE1:** Sunday, March 2, 2025\\n- **OPPE2:** Sunday, April 6, 2025\\n\\n### OPPE Slot Allocation:\\nDepending on eligibility for OPPE1 & OPPE2, students will be allocated one of three slots. Ensure availability on the given dates.\\n\\n### Eligibility for Bonus:\\n- The **SCT (System Compatibility Test)** is mandatory for the bonus to be added to the final score.\\n- Attendance in mock tests alone does **not** qualify for the bonus.\\n\\n## Eligibility Criteria\\n## Final Course Score Calculation:\\nFormula: **Capped at 100**.\\n\\nWhere:\\n- **GAA1:** Average score in the **best 10 out of 11** graded objective assignments.\\n- **GAA2:** Average score in the **best 10 out of 11** graded programming assignments.\\n- **Qz1:** Quiz 1 score (**0** if not attempted).\\n- **PE1:** OPPE1 score (**0** if not attempted).\\n- **PE2:** OPPE2 score (**0** if not attempted).\\n- **F:** Final exam score.\\n\\n---\\n\\n# Lecture Content\\n## Eligibility Criteria\\n\\n### OPPE1:\\n- Completion of the **OPPE System Compatibility Test (SCT)** is mandatory.\\n- OPPE1 will **not** be scheduled for students who fail the SCT.\\n\\n### OPPE2:\\n- **GrPA (Graded Programming Assignments):** Average of the best **5 out of the first 7** scores must be **≥ 40/100**.\\n- **Weekly Assessments:** Average of the best **5 out of the first 7** (objective + programming) scores must be **≥ 40/100**.\\n\\n### End Term Exam:\\n- The **weekly assessments** (objective + programming) must have an **average score of ≥ 40/100**.\\n\\n## Final Course Grade Requirements:\\n- Must attend the **End Term Exam**.\\n- Must score **≥ 40/100** in at least **one programming exam** (OPPE1 or OPPE2).', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(reterive_context(\"Can you tell me about the grading of the python course\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_autobot(user_query,reterived_context):\n",
    "   return autobot.invoke({\"user_query\":user_query,\"retrieved_context\":reterived_context})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grading for the **Intro to Python Programming** course is based on the following components:\n",
      "\n",
      "1. **Graded Objective Assignments (GAA1):**  \n",
      "   - The average score of the **best 10 out of 11** graded objective assignments.\n",
      "\n",
      "2. **Graded Programming Assignments (GAA2):**  \n",
      "   - The average score of the **best 10 out of 11** graded programming assignments.\n",
      "\n",
      "3. **Quiz 1 (Qz1):**  \n",
      "   - The score of Quiz 1 (if not attempted, the score is **0**).\n",
      "\n",
      "4. **Programming Exams (OPPE):**  \n",
      "   - **OPPE1 (PE1):** Score of the first programming exam (if not attempted, the score is **0**).  \n",
      "   - **OPPE2 (PE2):** Score of the second programming exam (if not attempted, the score is **0**).\n",
      "\n",
      "5. **Final Exam (F):**  \n",
      "   - The score of the end-term exam.\n",
      "\n",
      "### Final Course Score Calculation:\n",
      "The final score is calculated using the formula:  \n",
      "**Final Score = min(100, 0.15 × GAA1 + 0.15 × GAA2 + 0.10 × Qz1 + 0.20 × PE1 + 0.20 × PE2 + 0.20 × F)**\n",
      "\n",
      "### Additional Notes:\n",
      "- The final score is **capped at 100**.\n",
      "- To pass the course, students must:  \n",
      "  - Attend the **End Term Exam**.  \n",
      "  - Score **≥ 40/100** in at least **one programming exam** (OPPE1 or OPPE2).  \n",
      "\n",
      "Let me know if you need further clarification!\n"
     ]
    }
   ],
   "source": [
    "user_query=\"Tell me about the grading subject of the python course\"\n",
    "reterived_context = reterive_context(user_query)\n",
    "response = call_autobot(user_query,reterived_context)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
